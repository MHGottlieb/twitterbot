consumer_secret = consumer_secret)
user <- "MHGottlieb"
#Henter likes fra twitter og frasorterer irrelevant info
favs <- get_favorites(user, n=3000)
favs <- favs[c(1:5, 15,29:30,85)]
favs <- favs[which(favs$lang %in% c("da", "en")),]
favs$emojis <- str_match_all(favs$text,"\\p{So}|\\p{Cn}") #udskiller emojis
favs$text <- gsub("\\p{So}|\\p{Cn}| ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", "", favs$text, perl=TRUE) #fjerner emojis og links fra tekst.
#Timeline for reference in traning (negative cases)
timeline <- get_my_timeline(user=user, n=800)
timeline <- timeline[c(1:5, 15,29:30,85)]
timeline <- timeline[which(timeline$lang %in% c("da", "en")),]
timeline$emojis <- str_match_all(timeline$text,"\\p{So}|\\p{Cn}") #udskiller emojis
timeline$text <- gsub("\\p{So}|\\p{Cn}| ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", "", timeline$text, perl=TRUE) #fjerner emojis og links fra tekst.
timeline_dk <- timeline[timeline$lang=="da",]
favs_dk <- favs[favs$lang=="da",]
remove(favs, timeline, consumer_key, consumer_secret, user)
# Opretter og traener modellen --------------------------------------------
#Training-set, bestaaende af...
train_dk <- sample_n(favs_dk, 400) #...400 tilfældige tweets, jeg har liket
train_dk <- rbind(train_dk, sample_n(timeline_dk, nrow(timeline_dk)/2)) #...og et antal tilfældige (danske) tweets
train_dk$corpus <- c(rep("like", 400), rep("not like", nrow(timeline_dk)/2)) # Classifiers
train_dk$corpus <- as.factor(train_dk$corpus)
#Test-set, bestående af
test_dk <- favs_dk[which(!favs_dk$status_id %in% train_dk$status_id),] #tweets, jeg har liket
test_like <- nrow(test_dk)
test_dk <- rbind(test_dk, timeline_dk[which(!timeline_dk$status_id %in% train_dk$status_id),]) # tilfældige tweets
test_dk$corpus <- c(rep("like", test_like), rep("not like", nrow(test_dk)-test_like))
test_dk$corpus <- as.factor(test_dk$corpus)
#Rydder op (Turn down for what?)
remove(favs_dk, timeline_dk, test_like)
train <- VCorpus(VectorSource(train_dk$text), readerControl=list(language="Danish"))
train <- tm_map(train, content_transformer(stripWhitespace))
train <- tm_map(train, content_transformer(removeNumbers))
train <- tm_map(train, content_transformer(removePunctuation))
test <- VCorpus(VectorSource(test_dk$text), readerControl=list(language="Danish"))
test <- tm_map(test, content_transformer(stripWhitespace))
test <- tm_map(test, content_transformer(removeNumbers))
test <- tm_map(test, content_transformer(removePunctuation))
train.dtm <- as.matrix(DocumentTermMatrix(train, control=list(wordLengths=c(1,Inf))))
test.dtm <- as.matrix(DocumentTermMatrix(test, control=list(wordLengths=c(1,Inf))))
train.df <- data.frame(train.dtm[,intersect(colnames(train.dtm), colnames(test.dtm))])
test.df <- data.frame(test.dtm[,intersect(colnames(test.dtm), colnames(train.dtm))])
train.df$corpus <- train_dk$corpus
test.df$corpus <- test_dk$corpus
df.train <- train.df
df.test <- test.df
type <- c("C-svc", "nu-svc", "C-bsvc")
kernels <- c("rbfdot", "polydot", "vanilladot", "tanhdot", "laplacedot",
"besseldot", "anovadot")
cms <- data.frame()
h <- 1
for(i in 1:length(type)){
for(y in 1:length(kernels)){
tryCatch({
df.model <- ksvm(corpus~., data= df.train, kernel=kernels[y], type=type[i])
df.pred <- predict(df.model, df.test)
con.matrix <- confusionMatrix(df.pred, df.test$corpus)
message(paste(i, "/", y, type[i], "/ kernel:", kernels[y]))
print(con.matrix[2])
cms$run[h] <- paste(type[i], "/ kernel:", kernels[y])
cms$accuracy[h] <- con.matrix[3][[1]][1]
h <- h+1
}, error = function(){
message(paste("Error: ", i, "/", y, type[i], "/ kernel:", kernels[y]))
})
}
}
cms <- data.frame()
h <- 1
for(i in 1:length(type)){
for(y in 1:length(kernels)){
df.model <- ksvm(corpus~., data= df.train, kernel=kernels[y], type=type[i])
df.pred <- predict(df.model, df.test)
con.matrix <- confusionMatrix(df.pred, df.test$corpus)
message(paste(i, "/", y, type[i], "/ kernel:", kernels[y]))
print(con.matrix[2])
cms$run[h] <- paste(type[i], "/ kernel:", kernels[y])
cms$accuracy[h] <- con.matrix[3][[1]][1]
h <- h+1
}
}
cms$run[h] <- paste(type[i], "/ kernel:", kernels[y])
cms <- NULL
cms$run[h] <- paste(type[i], "/ kernel:", kernels[y])
cms$accuracy[h] <- con.matrix[3][[1]][1]
View(cms)
cms <- as.data.frame(run=character(), accuracy=double())
cms <- data.frame(run=character(), accuracy=double())
h <- 1
for(i in 1:length(type)){
for(y in 1:length(kernels)){
df.model <- ksvm(corpus~., data= df.train, kernel=kernels[y], type=type[i])
df.pred <- predict(df.model, df.test)
con.matrix <- confusionMatrix(df.pred, df.test$corpus)
message(paste(i, "/", y, type[i], "/ kernel:", kernels[y]))
print(con.matrix[2])
cms$run[h] <- paste(type[i], "/ kernel:", kernels[y])
cms$accuracy[h] <- con.matrix[3][[1]][1]
h <- h+1
}
}
cms$run[1]
cms$run[1] <- "hej"
rbind(cms, c(paste(type[i], "/ kernel:", kernels[y]), con.matrix[3][[1]][1]))
con.matrix[3][[1]][1]
con.matrix[3][[1]][1]
con.matrix[3][[1]][1][1]
con.matrix[3][[1]][1]*1
c(paste(type[i], "/ kernel:", kernels[y]), con.matrix[3][[1]][1])
cms <- rbind(cms, c(paste(type[i], kernels[y]), con.matrix[3][[1]][1]))
View(cms)
cms <- data.frame(run=character(), accuracy=double())
h <- 1
for(y in 1:length(kernels)){
df.model <- ksvm(corpus~., data= df.train, kernel=kernels[y], type=type[i])
df.pred <- predict(df.model, df.test)
con.matrix <- confusionMatrix(df.pred, df.test$corpus)
message(paste(i, "/", y, type[i], "/ kernel:", kernels[y]))
print(con.matrix[2])
cms <- rbind(cms, c(paste(type[i], kernels[y]), con.matrix[3][[1]][1]))
h <- h+1
}
type <- c("C-svc", "nu-svc", "C-bsvc")
kernels <- c("rbfdot", "polydot", "vanilladot", "tanhdot", "laplacedot",
"besseldot", "anovadot")
cms <- data.frame(run=character(), accuracy=double())
h <- 1
for(i in 1:length(type)){
for(y in 1:length(kernels)){
df.model <- ksvm(corpus~., data= df.train, kernel=kernels[y], type=type[i])
df.pred <- predict(df.model, df.test)
con.matrix <- confusionMatrix(df.pred, df.test$corpus)
message(paste(i, "/", y, type[i], "/ kernel:", kernels[y]))
print(con.matrix[2])
cms <- rbind(cms, c(paste(type[i], kernels[y]), con.matrix[3][[1]][1]))
h <- h+1
}
}
View(cms)
warnings()
cms <- data.frame(run, accuracy)
h <- 1
for(i in 1:length(type)){
for(y in 1:length(kernels)){
df.model <- ksvm(corpus~., data= df.train, kernel=kernels[y], type=type[i])
df.pred <- predict(df.model, df.test)
con.matrix <- confusionMatrix(df.pred, df.test$corpus)
message(paste(i, "/", y, type[i], "/ kernel:", kernels[y]))
print(con.matrix[2])
cms <- rbind(cms, c(paste(type[i], kernels[y]), con.matrix[3][[1]][1]))
h <- h+1
}
}
View(cms)
warnings?
()
warnings()
cms <- append(cms, c(paste(type[i], kernels[y]), con.matrix[3][[1]][1]))
View(cms)
cms <- NULL
cms <- append(cms, c(paste(type[i], kernels[y]), con.matrix[3][[1]][1]))
cms <- append(cms, c(paste(type[i], kernels[y]), con.matrix[3][[1]][1]))
cms <- append(cms, c(paste(type[i], kernels[y]), con.matrix[3][[1]][1]))
cms <- NULL
cms <- NULL
acc <- NULL
h <- 1
for(i in 1:length(type)){
for(y in 1:length(kernels)){
df.model <- ksvm(corpus~., data= df.train, kernel=kernels[y], type=type[i])
df.pred <- predict(df.model, df.test)
con.matrix <- confusionMatrix(df.pred, df.test$corpus)
message(paste(i, "/", y, type[i], "/ kernel:", kernels[y]))
print(con.matrix[2])
cms <- append(cms, paste(type[i], kernels[y]))
acc <- append(acc, con.matrix[3][[1]][1]))
}
}
for(i in 1:length(type)){
for(y in 1:length(kernels)){
df.model <- ksvm(corpus~., data= df.train, kernel=kernels[y], type=type[i])
df.pred <- predict(df.model, df.test)
con.matrix <- confusionMatrix(df.pred, df.test$corpus)
message(paste(i, "/", y, type[i], "/ kernel:", kernels[y]))
print(con.matrix[2])
cms <- append(cms, paste(type[i], kernels[y]))
acc <- append(acc, con.matrix[3][[1]][1]))
}
}
for(i in 1:length(type)){
for(y in 1:length(kernels)){
df.model <- ksvm(corpus~., data= df.train, kernel=kernels[y], type=type[i])
df.pred <- predict(df.model, df.test)
con.matrix <- confusionMatrix(df.pred, df.test$corpus)
message(paste(i, "/", y, type[i], "/ kernel:", kernels[y]))
print(con.matrix[2])
cms <- append(cms, paste(type[i], kernels[y]))
acc <- append(acc, con.matrix[3][[1]][1]))
}
}
for(i in 1:length(type)){
for(y in 1:length(kernels)){
df.model <- ksvm(corpus~., data= df.train, kernel=kernels[y], type=type[i])
df.pred <- predict(df.model, df.test)
con.matrix <- confusionMatrix(df.pred, df.test$corpus)
message(paste(i, "/", y, type[i], "/ kernel:", kernels[y]))
print(con.matrix[2])
cms <- append(cms, paste(type[i], kernels[y]))
acc <- append(acc, con.matrix[3][[1]][1])
}
}
out <- cbind(cms, acc)
out
plot(out[2])
plot(out[,2])
out[order(out[,2])]
order(out[,2])
out <- out[order(out[,2]),]
out
plot(out[,2])
df.model <- ksvm(corpus~., data= df.train, kernel="polydot", type="C-svc")
df.pred <- predict(df.model, df.test)
con.matrix <- confusionMatrix(df.pred, df.test$corpus)
print(con.matrix)
df.model <- ksvm(corpus~., data= df.train, kernel="vanilladot", type="C-svc")
df.pred <- predict(df.model, df.test)
con.matrix <- confusionMatrix(df.pred, df.test$corpus)
print(con.matrix)
library(rtweet)
library(caret)
library(tm)
library(kernlab)
library(dplyr)
library(splitstackshape)
library(stringr)
library("e1071")
# skaber token
consumer_key <- readLines("Keychain/consumer_key.txt", warn=FALSE)
consumer_secret <- readLines("Keychain/secret_key.txt", warn=FALSE)
token <- create_token(
app = "Helge",
consumer_key = consumer_key,
consumer_secret = consumer_secret)
user <- "MHGottlieb"
#Henter likes fra twitter og frasorterer irrelevant info
favs <- get_favorites(user, n=3000)
favs <- favs[c(1:5, 15,29:30,85)]
favs <- favs[which(favs$lang %in% c("da", "en")),]
favs$emojis <- str_match_all(favs$text,"\\p{So}|\\p{Cn}") #udskiller emojis
favs$text <- gsub("\\p{So}|\\p{Cn}| ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", "", favs$text, perl=TRUE) #fjerner emojis og links fra tekst.
#Timeline for reference in traning (negative cases)
timeline <- get_my_timeline(user=user, n=1000)
timeline <- timeline[c(1:5, 15,29:30,85)]
timeline <- timeline[which(timeline$lang %in% c("da", "en")),]
timeline$emojis <- str_match_all(timeline$text,"\\p{So}|\\p{Cn}") #udskiller emojis
timeline$text <- gsub("\\p{So}|\\p{Cn}| ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", "", timeline$text, perl=TRUE) #fjerner emojis og links fra tekst.
timeline_dk <- timeline[timeline$lang=="da",]
favs_dk <- favs[favs$lang=="da",]
remove(favs, timeline, consumer_key, consumer_secret, user)
#Training-set, bestaaende af...
train_dk <- sample_n(favs_dk, nrow(favs_dk)-100) #...400 tilfældige tweets, jeg har liket
train_dk <- rbind(train_dk, sample_n(timeline_dk, nrow(timeline_dk)/2)) #...og et antal tilfældige (danske) tweets
nrow(favs_dk)-100
#Training-set, bestaaende af...
train_dk <- sample_n(favs_dk, nrow(favs_dk)-100) #...400 tilfældige tweets, jeg har liket
train_dk <- rbind(train_dk, sample_n(timeline_dk, nrow(timeline_dk)/2)) #...og et antal tilfældige (danske) tweets
#Training-set, bestaaende af...
ntrain <- nrow(favs_dk)
train_dk <- sample_n(favs_dk, ntrain-100) # et antal tilfældige tweets, jeg har liket
train_dk <- rbind(train_dk, sample_n(timeline_dk, nrow(timeline_dk)/2)) #...og et antal tilfældige (danske) tweets
train_dk$corpus <- c(rep("like", ntrain-100), rep("not like", nrow(timeline_dk)/2)) # Classifiers
train_dk$corpus <- as.factor(train_dk$corpus)
# skaber token
consumer_key <- readLines("Keychain/consumer_key.txt", warn=FALSE)
consumer_secret <- readLines("Keychain/secret_key.txt", warn=FALSE)
token <- create_token(
app = "Helge",
consumer_key = consumer_key,
consumer_secret = consumer_secret)
user <- "MHGottlieb"
#Henter likes fra twitter og frasorterer irrelevant info
favs <- get_favorites(user, n=3000)
favs <- favs[c(1:5, 15,29:30,85)]
favs <- favs[which(favs$lang %in% c("da", "en")),]
favs$emojis <- str_match_all(favs$text,"\\p{So}|\\p{Cn}") #udskiller emojis
favs$text <- gsub("\\p{So}|\\p{Cn}| ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", "", favs$text, perl=TRUE) #fjerner emojis og links fra tekst.
#Timeline for reference in traning (negative cases)
timeline <- get_my_timeline(user=user, n=1000)
timeline <- timeline[c(1:5, 15,29:30,85)]
timeline <- timeline[which(timeline$lang %in% c("da", "en")),]
timeline$emojis <- str_match_all(timeline$text,"\\p{So}|\\p{Cn}") #udskiller emojis
timeline$text <- gsub("\\p{So}|\\p{Cn}| ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", "", timeline$text, perl=TRUE) #fjerner emojis og links fra tekst.
timeline_dk <- timeline[timeline$lang=="da",]
favs_dk <- favs[favs$lang=="da",]
remove(favs, timeline, consumer_key, consumer_secret, user)
# Opretter og traener modellen --------------------------------------------
#Training-set, bestaaende af...
ntrain <- nrow(favs_dk)
train_dk <- sample_n(favs_dk, ntrain-100) # et antal tilfældige tweets, jeg har liket
train_dk <- rbind(train_dk, sample_n(timeline_dk, nrow(timeline_dk)/2)) #...og et antal tilfældige (danske) tweets
train_dk$corpus <- c(rep("like", ntrain-100), rep("not like", nrow(timeline_dk)/2)) # Classifiers
train_dk$corpus <- as.factor(train_dk$corpus)
# skaber token
consumer_key <- readLines("Keychain/consumer_key.txt", warn=FALSE)
consumer_secret <- readLines("Keychain/secret_key.txt", warn=FALSE)
user <- "MHGottlieb"
#Timeline for reference in traning (negative cases)
timeline <- get_my_timeline(user=user, n=1000)[c(1:5, 15,29:30,85)]
library(magrittr)
regex <- c(emojis = "\\p{So}|\\p{Cn}",
links = "?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)")
emojis
regex$emojis
regex.emojis
regex
regex
regx <- c(emoji = "\\p{So}|\\p{Cn}",
link = "?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)")
regx.emoji
regx$$emoji
regx["emoji"]
message(regx["emoji"])
remove(regex, regx)
reg <- c(emj = "\\p{So}|\\p{Cn}",
lnk = "?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)")
gsub(reg["lnk"], "", favs$text, perl=TRUE)
#Henter likes fra twitter og frasorterer irrelevant info
favs <- get_favorites(user, n=3000)
gsub(reg["lnk"], "", favs$text, perl=TRUE)[1:10]
gsub(reg["lnk"], "", favs$text, perl=TRUE)
reg <- c(emj = "\\p{So}|\\p{Cn}", lnk = " ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)")
reg["lnk"]
gsub(reg["lnk"], "", favs$text, perl=TRUE)
gsub(reg["lnk"], "", favs$text, perl=TRUE)[1:10]
gsub(reg["lnk"], "", favs$text)[1:10]
regex
reg
paste(reg)
reg.emoji <- "\\p{So}|\\p{Cn}"
reg.link <- " ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)"
gsub(reg.emoji|reg.link, "", favs$text, perl=TRUE)[1:10]
reg.both <- paste0(reg.emoji, "|", reg.link)
paste0(reg.emoji, "|", reg.link)
paste(reg.emoji, "|", reg.link)
# Getting Data from Twitter -----------------------------------------------
# skaber token
consumer_key <- readLines("Keychain/consumer_key.txt", warn=FALSE)
consumer_secret <- readLines("Keychain/secret_key.txt", warn=FALSE)
token <- create_token(
app = "Helge",
consumer_key = consumer_key,
consumer_secret = consumer_secret)
user <- "MHGottlieb"
reg.emoji <- "\\p{So}|\\p{Cn}"
reg.link <- " ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)"
reg.both <- paste0(reg.emoji, "|", reg.link)
#Henter likes fra twitter og frasorterer irrelevant info
favs <- get_favorites(user, n=3000)
favs$emojis <- str_match_all(favs$text, reg.emoji])
favs$text <- gsub(reg.both, "", favs$text, perl=TRUE)
favs$text <- gsub(reg.both, "", favs$text, perl=TRUE)[1:10]
gsub(reg.both, "", favs$text, perl=TRUE)[1:10]
reg.both <- paste0(reg.emoji, "|", reg.link, "|", reg.nl)
reg.nl <- "[\n]+"
reg.both <- paste0(reg.emoji, "|", reg.link, "|", reg.nl)
gsub(reg.both, "", favs$text, perl=TRUE)[1:10]
abe <- c(reg.link, reg.nl, reg.emoji)
paste(abe)
paste(abe, collapse="")
paste(abe, collapse="|")
reg <- c(emoji = "\\p{So}|\\p{Cn}", nl = "[\n]+",
link = " ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)")
reg
reg[]
reg[[]]
reg
paste(reg, collapse="")
# skaber token
consumer_key <- readLines("Keychain/consumer_key.txt", warn=FALSE)
consumer_secret <- readLines("Keychain/secret_key.txt", warn=FALSE)
token <- create_token(
app = "Helge",
consumer_key = consumer_key,
consumer_secret = consumer_secret)
# brugbare variable og regex
user <- "MHGottlieb"
reg <- c(emoji = "\\p{So}|\\p{Cn}", nl = "[\n]+",
link = " ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)")
#Henter likes fra twitter og frasorterer irrelevant info
favs <- get_favorites(user, n=3000)
favs$emojis <- str_match_all(favs$text, reg["emoji"])
favs$text <- gsub(paste(reg, collapse="|"), "", favs$text, perl=TRUE)
tweets <- get_my_timeline(user=user, n=1000)
tweets$emojis <- str_match_all(favs$text, reg["emoji"])
tweets$text <- gsub(paste(reg, collapse="|"), "", favs$text, perl=TRUE)
View(favs)
names(favs)==names(tweets)
favs <- get_favorites(user, n=3000)
favs$emojis <- str_match_all(favs$text, reg["emoji"])
favs$text <- gsub(paste(reg, collapse="|"), "", favs$text, perl=TRUE)
tweets <- get_my_timeline(user=user, n=1000)
tweets$emojis <- str_match_all(tweets$text, reg["emoji"])
tweets$text <- gsub(paste(reg, collapse="|"), "", tweets$text, perl=TRUE)
names(favs)==names(tweets)
View(tweets)
View(favs)
#Henter likes fra twitter og frasorterer irrelevant info
favs <- get_favorites(user, n=3000)[c(1:5, 15,29:30,85)]
favs$emojis <- str_match_all(favs$text, reg["emoji"])
favs$text <- gsub(paste(reg, collapse="|"), "", favs$text, perl=TRUE)
tweets <- get_my_timeline(user=user, n=1000)[c(1:5, 15,29:30,85)]
tweets$emojis <- str_match_all(tweets$text, reg["emoji"])
tweets$text <- gsub(paste(reg, collapse="|"), "", tweets$text, perl=TRUE)
nrow(tweets[tweets$lang=="da"])
length(tweets[tweets$lang=="da"])
sum(tweets[tweets$lang=="da"])
tweets[tweets$lang=="da",]
library(rtweet)
library(caret)
library(tm)
library(kernlab)
library(dplyr)
library(splitstackshape)
library(stringr)
library(e1071)
library(magrittr)
hej <- get_my_timeline(user=user, n=1000)[c(1:5, 15,29:30,85)]
users_data(hej[1:10])
hej <- get_my_timeline(user=user, n=1000)
users_data(hej)[1,]
tweet_shot(get_favorites(user, n=1)
)
my_timeline< <- get_timeline(user, n=3200)
my_timeline <- get_timeline(user, n=3200)
ts_plot(my_timeline)
suggested_slugs(user)
hej <- NULL
hej <- NULL
Sys.time()
as.integer(Sys.time())
as.integer(Sys.time())
as.integer(as.POSIXct("2018-11-04 14:00:00 CET"))
as.integer(as.POSIXct("2018-11-04 14:00:00 CET"))
Sys.time()<1541336400
1541323655
Sys.time()<1541323655
hej <- NULL
while(Sys.time()<1541336400){
temp <- get_my_timeline(user=user, n=200)[c(1:5, 15,29:30,85)]
hej <- unique(rbind(hej, temp))
message(paste0(nrow(hej, " unikke tweets hentet")))
Sys.sleep(300)
}
while(Sys.time()<1541336400){
temp <- get_my_timeline(user=user, n=200)[c(1:5, 15,29:30,85)]
hej <- unique(rbind(hej, temp))
message(paste0(nrow(hej), " unikke tweets hentet")))
Sys.sleep(300)
hej <- NULL
while(Sys.time()<1541336400){
temp <- get_my_timeline(user=user, n=200)[c(1:5, 15,29:30,85)]
hej <- unique(rbind(hej, temp))
message(paste0(nrow(hej), " unikke tweets hentet"))
Sys.sleep(300)
}
as.integer(as.POSIXct("2018-11-04 18:00:00 CET"))
while(Sys.time()<1541350800){
temp <- get_my_timeline(user=user, n=200)[c(1:5, 15,29:30,85)]
hej <- unique(rbind(hej, temp))
message(paste0(nrow(hej), " unikke tweets hentet"))
Sys.sleep(300)
}
while(Sys.time()<1541350800){
temp <- get_my_timeline(user=user, n=3200)[c(1:5, 15,29:30,85)]
hej <- unique(rbind(hej, temp))
message(paste0(nrow(hej), " unikke tweets hentet"))
Sys.sleep(300)
}
table[hej$lang]
nrow(hej[hej$lang=="da",])
?save.image
data <- hej
save.image(data, file="data.RData")
save.image(list=c("data"), file="data.RData")
save(data, file="data.RData")
save(data, file="tweets.RData")
save(data, file="tweets.RData")
while(Sys.time()<1541350800){
temp <- get_my_timeline(user=user, n=3200)[c(1:5, 15,29:30,85)]
data <- unique(rbind(data, temp))
message(paste0(nrow(data), " unikke tweets hentet"))
save(data, file="tweets.RData")
Sys.sleep(1800)
}
data <- unique(rbind(tweets, data))
while(Sys.time()<1541350800){
temp <- get_my_timeline(user=user, n=3200)[c(1:5, 15,29:30,85)]
data <- unique(rbind(data, temp))
message(paste0(nrow(data), " unikke tweets hentet"))
save(data, file="tweets.RData")
remove(temp)
Sys.sleep(1800)
}
while(Sys.time()<1541360800){
temp <- get_my_timeline(user=user, n=3200)[c(1:5, 15,29:30,85)]
data <- unique(rbind(data, temp))
message(paste0(nrow(data), " unikke tweets hentet"))
save(data, file="tweets.RData")
remove(temp)
Sys.sleep(1800)
}
